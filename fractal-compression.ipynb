{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание №2: Фрактальное сжатие\n",
    "\n",
    "ФИО: Трифонов Андрей Рафисович \n",
    "Группа: 213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Баллы за задание складываются из двух частей: баллы за выполнение промежуточных подзаданий и баллы за качество**\n",
    "\n",
    "**Максимальное количество баллов за выполнение промежуточных подзаданий — 15**\n",
    "\n",
    "**Баллы за качество выставляются по итогам сравнения всех решений**\n",
    "\n",
    "## Правила сдачи\n",
    "* У каждого подзадания указано максимальное количество баллов, которые можно за него получить\n",
    "* Для сдачи необходимо в Google Classroom загрузить Jupyter-ноутбук с выполненными подзаданиями\n",
    "* В некоторых ячейках есть строки (`# GRADED CELL: [function name]`), эти строки **менять нельзя**, они будет использоваться при проверке вашего решения\n",
    "* Интерфейс функций и классов помеченных таким образом должен остаться без изменений\n",
    "* Ячейка со строкой (`# GRADED CELL: [function name]`) должна содержать только **одну функцию или класс**\n",
    " * Лайфхак: функции можно определять внутри функций\n",
    "* Никакие другие ячейки не будут использованы при проверке, они должны быть самодостаточны\n",
    "* Запрещено импортировать иные библиотеки и функции, кроме указанных в первой ячейке с кодом  \n",
    "(если сильно захочется что-то еще импортировать, спросите в чате курса)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немного теории\n",
    "Алгоритм описан в главе про [сжатие изображений](https://compression.ru/book/part2/part2__3.htm#_Toc448152512).\n",
    "\n",
    "### Определения\n",
    "**Ранговый блок**: если исходное изображение разбивается на непересекающиеся блоки одинакового размера, замощающие всё изображение, то каждый такой блок называется *ранговым*; имеют меньший размер, чем доменные блоки.\n",
    "\n",
    "**Доменный блок**: если исходное изображение разбивается блоки одинакового размера, которые могут и пересекаться, то каждый такой блок называется *доменным*; имеют больший размер, чем ранговые блоки.\n",
    "\n",
    "**Идея алгоритма**:\n",
    "\n",
    "При сжатии:\n",
    "1. для каждого рангового блока найти наиболее похожий на него доменный блок (с учётом поворотов и симметрии)\n",
    "2. выполнить преобразование яркости\n",
    "3. в качестве сжатого изображения выступают коэффициенты преобразования ранговых блоков, эффективно записанные в файл (строку)\n",
    "\n",
    "При декомпрессии:\n",
    "1. Прочитать файл (строку), извлечь коэффициенты преобразований\n",
    "2. Применить преобразования к исходному изображению (обычно просто серое) пока результат не стабилизируется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python Library\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# Additional Modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from skimage import data, img_as_float64\n",
    "from skimage.metrics import mean_squared_error as mse, peak_signal_noise_ratio as psnr\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray, rgb2yuv, yuv2rgb\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом нужно загрузить картинку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_rgb_512x512 = io.imread('test_files/lenna.bmp')\n",
    "lenna_rgb_256x256 = resize(lenna_rgb_512x512, (256, 256))\n",
    "lenna_gray_256x256 = np.rint(rgb2gray(lenna_rgb_256x256) * 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plt` — модуль для рисования графиков и всего остального\n",
    "\n",
    "Очень удобная штука, будем пользоваться ей довольно часто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(lenna_gray_256x256, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общие функции\n",
    "В следующих клетках описаны функции и классы, которые будут использоваться **вами** при выполнении следующих подзаданий. Стоит с ними подробно ознакомиться, понять, что они делают, и поэкспериментировать.\n",
    "\n",
    "**Не следует их менять.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BlockTransform = namedtuple('BlockTransform', ['x', 'y', 'di', 'tr'])\n",
    "FractalCompressionParams = namedtuple(\n",
    "    'FractalCompressionParams', [\n",
    "        'height',\n",
    "        'width',\n",
    "        'is_colored',\n",
    "        'block_size',\n",
    "        'spatial_scale',\n",
    "        'intensity_scale',\n",
    "        'stride'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_num_bits(length, stride):\n",
    "    return np.ceil(np.log2(length / stride)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_colored(image):\n",
    "    if len(image.shape) == 2:\n",
    "        return False\n",
    "    elif len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "        return True\n",
    "    else:\n",
    "        message = 'Invalid shape of the image: `{}`'\n",
    "        raise ValueError(message.format(image.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 балла] Функция для нахождения наилучшего преобразования рангового блока\n",
    "\n",
    "#### Описание\n",
    "\n",
    "на входе функции подаются:\n",
    "* исходное Ч/Б изображение (`image`)\n",
    "* уменьшенное изображение (`resized_image`)\n",
    "* координаты рангового блока (`x`, `y`)\n",
    "* размер блока (`block_size`)\n",
    "* шаг, через сколько пикселей перескакивать при переборе (`stride`)\n",
    "\n",
    "на выходе функция должна выдавать:\n",
    "* лучшее преобразование в смысле MSE, объект типа `BlockTransform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: find_block_transform\n",
    "\n",
    "def find_block_transform(image, resized_image, x, y, block_size=8, stride=1, intensity=0.75):\n",
    "    '''Find best transformation for given rank block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source B/W image.\n",
    "\n",
    "    resized_image: np.array\n",
    "        Resized source image.\n",
    "\n",
    "    x, y: int, int\n",
    "        Coordinates of the rank block.\n",
    "    \n",
    "    block_size: int\n",
    "        Size of rank block.\n",
    "\n",
    "    stride: int\n",
    "        Vertical and horizontal stride for domain block search.\n",
    "    \n",
    "    intensity: float\n",
    "        Brightness scaling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_transform: BlockTransform\n",
    "        Best transformation.\n",
    "    '''\n",
    "    trs = np.arange(8)\n",
    "    domain_xs = np.arange(0, resized_image.shape[0] - block_size + 1, stride)\n",
    "    domain_ys = np.arange(0, resized_image.shape[1] - block_size + 1, stride)\n",
    "    \n",
    "    def img2domain_blocks(img):\n",
    "        domain_blocks = []\n",
    "        \n",
    "        imgs4trs = np.array([img for tr in trs])\n",
    "        for tr in range(1, 8):\n",
    "            imgs4trs[tr] = np.rot90(imgs4trs[tr - 1])\n",
    "        for tr in range(4, 8):\n",
    "            imgs4trs[tr] = np.fliplr(imgs4trs[tr])\n",
    "        \n",
    "        for tr, dm_x, dm_y in itertools.product(trs, domain_xs, domain_ys):\n",
    "            domain_blocks.append(imgs4trs[tr][dm_x:(dm_x + block_size),\n",
    "                                              dm_y:(dm_y + block_size)])\n",
    "        return domain_blocks\n",
    "    \n",
    "    # we may want to have a prebuilt array of domain blocks\n",
    "    if ((x, y) == (0, 0)):\n",
    "        find_block_transform.db_cache = img2domain_blocks(resized_image)\n",
    "    \n",
    "    domain_blocks = find_block_transform.db_cache # fetch Dij from cache\n",
    "    rank_block = image[x:(x + block_size), y:(y + block_size)]\n",
    "    pixels_in_block = block_size * block_size\n",
    "    \n",
    "    min_distance = 100000000000\n",
    "    domain_block_ID = 0\n",
    "    # best_block_ID = 0\n",
    "    for tr, dm_x, dm_y in itertools.product(trs, domain_xs, domain_ys):\n",
    "        domain_block = domain_blocks[domain_block_ID]\n",
    "        domain_block_ID += 1\n",
    "        di = (np.sum(domain_block) - np.sum(rank_block)) / pixels_in_block\n",
    "        current_distance = np.sum( np.square(rank_block * intensity +\n",
    "                                            np.full(rank_block.shape, di) -\n",
    "                                            domain_block) )\n",
    "        if (current_distance < min_distance):\n",
    "            min_distance = current_distance\n",
    "            best_transform = BlockTransform(dm_x, dm_y,\n",
    "                                            (int)(di), tr)\n",
    "            #best_block_ID = domain_block_ID\n",
    "    \n",
    "    return best_transform #, domain_blocks[best_block_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE INPUT CELL: find_block_transform\n",
    "\n",
    "#image = lenna_gray_256x256\n",
    "#spatial_scale = 0.5\n",
    "#new_size = (int(image.shape[0] * spatial_scale), int(image.shape[1] * spatial_scale))\n",
    "#resized_image = resize(image, new_size, anti_aliasing=True)\n",
    "#x = 8\n",
    "#y = 112\n",
    "#block_size = 8\n",
    "#stride = 1\n",
    "#intensity = 0.75\n",
    "#\n",
    "#rank_block = image[x:(x + block_size), y:(y + block_size)]\n",
    "#plt.imshow(rank_block, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TESTING CELL: find_block_transform\n",
    "#tr, best_block = find_block_transform(image, resized_image, x, y, block_size=8, stride=1, intensity=0.75)\n",
    "#plt.imshow(best_block, cmap='gray')\n",
    "#tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 балла] Применение IFS к изображению\n",
    "\n",
    "#### Описание\n",
    "\n",
    "на входе функции подаются:\n",
    "* исходное изображение (`image`)\n",
    "* уменьшенное изображение (`resized_image`)\n",
    "* IFS, массив объектов типа `BlockTransform` (`transforms`)\n",
    "* размер блока (`block_size`)\n",
    "\n",
    "на выходе функция должна выдавать:\n",
    "* картинку после одинарного применения IFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: perform_transform\n",
    "\n",
    "def perform_transform(image, resized_image, transforms, block_size):\n",
    "    '''Perform IFS on given image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source image.\n",
    "\n",
    "    resized_image: np.array\n",
    "        Resized source image.\n",
    "\n",
    "    transforms: list of BlockTransform's\n",
    "        Given IFS, Iterated Function System\n",
    "    \n",
    "    block_size: int\n",
    "        Size of rank block.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_image: np.array\n",
    "        Transformed image.\n",
    "    '''\n",
    "    \n",
    "    # genrating and image for all 90˚ rotations + mirror\n",
    "    def img_4_blocks(img):\n",
    "        trs = np.arange(8) \n",
    "        img_and_trs = np.array([resized_image for tr in trs])\n",
    "        \n",
    "        for tr in range(1, 8):\n",
    "            img_and_trs[tr] = np.rot90(img_and_trs[tr - 1])\n",
    "        for tr in range(4, 8):\n",
    "            img_and_trs[tr] = np.fliplr(img_and_trs[tr])\n",
    "            \n",
    "        return img_and_trs\n",
    "    \n",
    "    xs = np.arange(0, image.shape[0], block_size)\n",
    "    ys = np.arange(0, image.shape[1], block_size)\n",
    "    \n",
    "    transformed_image = image\n",
    "    \n",
    "    transform_ID = 0\n",
    "    imgs = img_4_blocks(resized_image)\n",
    "\n",
    "    for x, y in itertools.product(xs, ys):\n",
    "        t = transforms[transform_ID]\n",
    "        transform_ID += 1\n",
    "        transformed_image[x:(x + block_size),\n",
    "                          y:(y + block_size)\n",
    "            ] = -t.di + 0.75 * imgs[t.tr][t.x:(t.x + block_size), t.y:(t.y + block_size)]\n",
    "\n",
    "    return transformed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = comp.decompress(result_16x4, 2)\n",
    "plt.imshow(out, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [7 баллов] Класс, реализующий интерфейс битового массива\n",
    "Он понадобится для преобразования найденной IFS в строку, чтобы записать сжатый файл на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: BitBuffer\n",
    "\n",
    "class BitBuffer:\n",
    "    '''Class that provides storing and and reading integer numbers \n",
    "    in continuous bytearray.\n",
    "    \n",
    "    !!! BitBuffer is FIFO data structure !!!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    buffer : bytearray, optional (default=None)\n",
    "        Input bytearray, for initialization.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _buffer : bytearray\n",
    "        Bytearray that can contain any information.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> buffer = BitBuffer()\n",
    "    >>> buffer.push(1, 1)\n",
    "    >>> x = buffer.pop(1)\n",
    "    >>> print(x)\n",
    "    1\n",
    "    >>> buffer.push(125, 18)\n",
    "    >>> x = buffer.pop(18)\n",
    "    >>> print(x)\n",
    "    125\n",
    "    >>> buffer.push(5, 3)\n",
    "    >>> x = buffer.pop(3)\n",
    "    >>> print(x)\n",
    "    5\n",
    "\n",
    "    >>> dy = transform.y // stride\n",
    "    >>> buffer.push(dy, self._num_bits_ver)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, buffer=None):\n",
    "        self._buffer = buffer or bytearray()\n",
    "        # already (written/read) bits by previous (push/pop)\n",
    "        self._bits2ignore_push = 0\n",
    "        self._bits2ignore_pop = 0\n",
    "\n",
    "    def to_bytearray(self):\n",
    "        '''Convert to bytearray.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        buffer: bytearray\n",
    "            Bytearray that contains all data.\n",
    "        '''\n",
    "        \n",
    "        return self._buffer\n",
    "\n",
    "    def push(self, x, n_bits):\n",
    "        '''Push given integer to buffer. (append)\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : int\n",
    "            Input number.\n",
    "\n",
    "        n_bits: int\n",
    "            Number of bits for store input number,\n",
    "            should be greater than log2(x).\n",
    "        '''\n",
    "        \n",
    "        # shift x's bits closer to ending of written bits (b)\n",
    "        #                         (i i i) <- self._bits2ignore_push (written already)\n",
    "        # ... | b b b b  b b b b | b b b -  - - - - |\n",
    "        #                                x  x x 0 0 <- gap_remover (0)\n",
    "        \n",
    "        # (gap_remover == 8) <= (self._bits2ignore_push + n_bits == 8 * n), n > 0\n",
    "        # if so ending will be byte-like\n",
    "        \n",
    "        #print(\"debug dump 4 x=\", x)\n",
    "        gap_remover = 8 - (self._bits2ignore_push + n_bits) % 8 # [0; 8]\n",
    "        not_byte_sized = 1 if (gap_remover != 8) else 0\n",
    "        gap_remover %= 8 # preventing 8 bit x shift\n",
    "        x <<= gap_remover\n",
    "        \n",
    "        bytes_to_push = (self._bits2ignore_push + n_bits) // 8 + not_byte_sized\n",
    "        x = np.int64(x)\n",
    "        x_bytes = (x.item()).to_bytes(bytes_to_push, byteorder=\"big\", signed=False)\n",
    "        \n",
    "        # merge x's first and buffer's last byte\n",
    "        if (self._bits2ignore_push):\n",
    "            #print(\"gap remover:\", gap_remover)\n",
    "            #print(\"2ignore :\", self._bits2ignore_push)\n",
    "            #print(\"ending of buffer: \", self._buffer[-1], \"; ending of x_bytes: \", x_bytes)\n",
    "            self._buffer[-1] += x_bytes[0]\n",
    "            x_bytes = x_bytes[1:] # we dont want to append x's first later\n",
    "        \n",
    "        for byte in x_bytes:\n",
    "            self._buffer.append(byte)\n",
    "        \n",
    "        self._bits2ignore_push = (8 - gap_remover) % 8\n",
    "        \n",
    "    def pop(self, n_bits):\n",
    "        '''Pop n_bits from buffer and transform it to a number.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_bits: int\n",
    "            Number of bits for pop from buffer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x: int\n",
    "            Extracted number.\n",
    "        '''\n",
    "        \n",
    "        #print(self._bits2ignore_pop)\n",
    "        \n",
    "        #  (i i i)  <- self._bits2ignore_pop (read already)\n",
    "        # | ? ? ? x  x x x x | x b b b  b b b b | ...\n",
    "        # | ? ? ? x  x x x x | x(b b b  b b b b) <- aligner\n",
    "        # | ? ? ? ?  ? ? ? ? | ? ? x  x x x x x\n",
    "        \n",
    "        # (aligner == 8) <= (self._bits2ignore_pop + n_bits == 8 * n), n > 0\n",
    "        # if so beginning will be byte-like\n",
    "        \n",
    "        aligner = 8 - (self._bits2ignore_pop + n_bits) % 8 # [0; 8]\n",
    "        not_byte_sized = 1 if (aligner != 8) else 0\n",
    "        aligner %= 8 # preventing 8 bit x shift\n",
    "        \n",
    "        bytes_to_pop = (self._bits2ignore_pop + n_bits) // 8\n",
    "        bytes_to_read = bytes_to_pop + not_byte_sized\n",
    "        x_bytes = self._buffer[:bytes_to_read]\n",
    "        \n",
    "        x = int.from_bytes(x_bytes, byteorder='big', signed=False)\n",
    "        x >>= aligner\n",
    "        x &= 2 ** n_bits - 1\n",
    "        \n",
    "        self._buffer = self._buffer[bytes_to_pop:]\n",
    "        self._bits2ignore_pop = (8 - aligner) % 8\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Баллы за качество] Класс, реализующий интерфейс архиватора изображений\n",
    "\n",
    "#### Условие\n",
    "* Класс будет тестироваться как на черно-белых, так и на **цветных** изображениях\n",
    "* Для цветных изображений необходимо переходить в YUV, сжимать, а потом обратно в RGB для финального результата\n",
    "* В качестве оценки алгоритма будет использоваться кривая размер-качество, построенная на основе запуска метода compress2, с параметрами качества [0, 20, 40, 60, 80, 100]\n",
    "* Следует обеспечить непрерывную монотонную зависимость реального качества декодированного изображения от параметра качества\n",
    "* Баллы будут выставляться исходя из того, насколько построенный график размер-качество лежит близко к верхнему левому углу (высокое качество и низкий размер)\n",
    "* За красивые графики с равномерно распределенными узлами [0 ... 100] и без точек перегиба выставляются дополнительные баллы\n",
    "* Ограничение времени работы (суммарно сжатие и разжатие) на всех уровнях качества: 8 минут\n",
    "\n",
    "**Интерфейсом данного класса считаются только методы compress2 и decompress, остальные можно менять как угодно**`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: FractalCompressor\n",
    "\n",
    "class FractalCompressor:\n",
    "    '''Class that performs fractal compression/decompression of images.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _num_bits_ver : int\n",
    "        Number of bits for store VERTICAL OFFSET for each transformation.\n",
    "    \n",
    "    _num_bits_hor : int\n",
    "        Number of bits for store HORIZONTAL OFFSET for each transformation.\n",
    "        \n",
    "    _num_bits_pix : int\n",
    "        Number of bits for store INTENSITY OFFSET for each transformation.\n",
    "        \n",
    "    _num_bits_tfm : int\n",
    "        Number of bits for store TRANFORMATION INDEX for each transformation.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> comp = FractalCompressor()\n",
    "    >>> compressed_image = comp.compress(image, block_size=8, stride=2)\n",
    "    >>> decompressed_image = comp.decompress(compressed_image, num_iters=9)\n",
    "    >>> yet_another_compressed_image = comp.compress(image, 8, 4, 0.5, 0.7)\n",
    "    >>> yet_another_decompressed_image = comp.compress(yet_another_compressed_image, 5)\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self._num_bits_ver = None\n",
    "        self._num_bits_hor = None\n",
    "        self._num_bits_pix = 9\n",
    "        self._num_bits_tfm = 3\n",
    "    \n",
    "    # HEADER TAKES 7 BYTES OF BUFFER\n",
    "    # Binary header example:\n",
    "    # |00100000|000 00100|000000 0 0|00000100|0 0110010| 1001011 0|00000001| ...\n",
    "    \n",
    "    def _add_header(self, buffer, params):\n",
    "        '''Store header in buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "            \n",
    "        params: FractalCompressionParams\n",
    "            Parameters that should be stored in buffer.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_read_header`.\n",
    "        '''\n",
    "        \n",
    "        buffer.push(params.height, 11)\n",
    "        buffer.push(params.width, 11)\n",
    "        buffer.push(1 if (params.is_colored) else 0, 1)\n",
    "        buffer.push(params.block_size, 10)\n",
    "        buffer.push(int(params.spatial_scale * 100), 7)\n",
    "        buffer.push(int(params.intensity_scale * 100), 7)\n",
    "        buffer.push(params.stride, 9)\n",
    "    \n",
    "    def _read_header(self, buffer):\n",
    "        '''Read header from buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitiBuffer\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params: FractalCompressionParams\n",
    "            Extracted parameters.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_add_header`.\n",
    "        '''\n",
    "        \n",
    "        params = FractalCompressionParams(\n",
    "            buffer.pop(11),\n",
    "            buffer.pop(11),\n",
    "            buffer.pop(1) == 1,\n",
    "            buffer.pop(10),\n",
    "            buffer.pop(7) / 100,\n",
    "            buffer.pop(7) / 100,\n",
    "            buffer.pop(9)\n",
    "            )\n",
    "            \n",
    "        return params\n",
    "    \n",
    "    def _add_to_buffer(self, buffer, transform, stride):\n",
    "        '''Store block transformation in buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "        transform: BlockTransform\n",
    "            \n",
    "        stride: int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_read_transform`.\n",
    "        '''\n",
    "        \n",
    "        di_negative_flag = 1 if (transform.di < 0) else 0\n",
    "        di_unsigned = (abs(transform.di) << 1) + di_negative_flag\n",
    "        \n",
    "        buffer.push((int)( (transform.x / stride)  ), self._num_bits_hor)\n",
    "        buffer.push((int)( (transform.y / stride)  ), self._num_bits_ver)\n",
    "        buffer.push((int)(  di_unsigned            ), self._num_bits_pix)\n",
    "        buffer.push((int)( (transform.tr)          ), self._num_bits_tfm)\n",
    "        \n",
    "    def _read_transform(self, buffer, stride):\n",
    "        '''Read block transformation from buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "            \n",
    "        stride: int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        transform: BlockTransform\n",
    "            Extracted block transformation.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_add_to_buffer`.\n",
    "        '''\n",
    "\n",
    "        x = buffer.pop(self._num_bits_hor) * stride\n",
    "        y = buffer.pop(self._num_bits_ver) * stride\n",
    "        di_unsigned = buffer.pop(self._num_bits_pix)\n",
    "        di_sign = -1 if (di_unsigned % 2 == 1) else 1\n",
    "        \n",
    "        transform = BlockTransform (\n",
    "            x, y,\n",
    "            di_sign * (di_unsigned >> 1),\n",
    "            buffer.pop(self._num_bits_tfm)\n",
    "        )\n",
    "    \n",
    "        return transform\n",
    "    \n",
    "    def _ifs2buf(self, params, transformations):\n",
    "        '''Store compression parameters and IFS in buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        params: FractalCompressionParams\n",
    "            Parameters of the compression.\n",
    "\n",
    "        transformations: list of BlockTransform's\n",
    "            Given IFS.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_buf2ifs`.\n",
    "        '''\n",
    "        \n",
    "        buffer = BitBuffer()\n",
    "        self._add_header(buffer, params)\n",
    "        \n",
    "        self._num_bits_ver = derive_num_bits(params.height, params.stride)\n",
    "        self._num_bits_hor = derive_num_bits(params.width, params.stride)\n",
    "        \n",
    "        for t in transformations:\n",
    "            self._add_to_buffer(buffer, t, params.stride)\n",
    "        \n",
    "        return buffer\n",
    "    \n",
    "    def _buf2ifs(self, buffer):\n",
    "        '''Store compression parameters and IFS in buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params: FractalCompressionParams\n",
    "            Extracted compression parameters.\n",
    "\n",
    "        transforms: list of BlockTransform's\n",
    "            Extracted IFS.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_ifs2buf`.\n",
    "        '''\n",
    "\n",
    "        params = self._read_header(buffer)\n",
    "        \n",
    "        self._num_bits_ver = derive_num_bits(params.height, params.stride)\n",
    "        self._num_bits_hor = derive_num_bits(params.width, params.stride)\n",
    "        \n",
    "        num_transforms = int(params.height * params.width / params.block_size ** 2)\n",
    "        transforms = [\n",
    "            self._read_transform(buffer, params.stride)\n",
    "            for _ in range(num_transforms)\n",
    "        ]\n",
    "        \n",
    "        return params, transforms\n",
    "        \n",
    "    def compress(self, image, block_size=8, stride=1,\n",
    "                 spatial_scale=0.5, intensity_scale=0.75):\n",
    "        '''Compress input image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    "\n",
    "        block_size: int, optional (default = 8)\n",
    "            Size of rank block.\n",
    "\n",
    "        stride: int, optional (default = 1)\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "        \n",
    "        spatial_scale : float, optional (default = 0.5)\n",
    "            ({rank block size} / {domain block size}) ratio, must be < 1.\n",
    "        \n",
    "        intensity_scale : float, optional (default = 0.75)\n",
    "            Reduce coefficient for image intensity.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `decompress`.\n",
    "        '''\n",
    "        spatial_scale = round(spatial_scale, 2)\n",
    "        intensity_scale = round(intensity_scale, 2)\n",
    "        \n",
    "        new_size = (\n",
    "            int(image.shape[0] * spatial_scale),\n",
    "            int(image.shape[1] * spatial_scale)\n",
    "        )\n",
    "        resized_image = resize(image, new_size, anti_aliasing=False, preserve_range=True)\n",
    "        \n",
    "        xs = np.arange(0, image.shape[0], block_size)\n",
    "        ys = np.arange(0, image.shape[1], block_size)\n",
    "        \n",
    "        transformations = []\n",
    "        for x, y in tqdm(itertools.product(xs, ys), total=len(xs)*len(ys)):\n",
    "            transform = find_block_transform(\n",
    "                image, resized_image, x, y,\n",
    "                block_size, stride, intensity_scale\n",
    "            )\n",
    "            transformations.append(transform)\n",
    "        \n",
    "        params = FractalCompressionParams(\n",
    "            image.shape[0],\n",
    "            image.shape[1],\n",
    "            is_colored(image),\n",
    "            block_size,\n",
    "            spatial_scale,\n",
    "            intensity_scale,\n",
    "            stride\n",
    "        )\n",
    "        \n",
    "        buffer = self._ifs2buf(params, transformations)\n",
    "        return buffer.to_bytearray()\n",
    "            \n",
    "    def compress2(self, image, quality=50):\n",
    "        '''Compress input image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    "\n",
    "        quality: int, optional (default=50)\n",
    "            Quality of image compression\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `decompress`.\n",
    "        '''\n",
    "            \n",
    "        # FEEL FREE TO CHANGE CODE BELOW\n",
    "            \n",
    "        return self.compress(image)\n",
    "    \n",
    "    def decompress(self, byte_array, num_iters=10):\n",
    "        '''Decompress input image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "\n",
    "        num_iters: int, optional (default=10)\n",
    "            Number of iterations to perform IFS.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image: np.array\n",
    "            Decompressed image.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `compress`.\n",
    "        '''\n",
    "        \n",
    "        params, transforms = self._buf2ifs(BitBuffer(byte_array))\n",
    "        \n",
    "        # inital image is black\n",
    "        image = lenna_gray_256x256 - lenna_gray_256x256\n",
    "        \n",
    "        new_size = (\n",
    "            int(image.shape[0] * params.spatial_scale),\n",
    "            int(image.shape[1] * params.spatial_scale)\n",
    "        )\n",
    "        \n",
    "        for i in range(num_iters):\n",
    "            resized_image = resize(image, new_size, anti_aliasing=False,preserve_range=True)\n",
    "            image = perform_transform(\n",
    "                    image, resized_image,\n",
    "                    transforms, params.block_size\n",
    "            )\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пробуем применить FractalCompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = FractalCompressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_16x4 = comp.compress(lenna_gray_256x256, block_size=16, stride=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер сжатого изображения в байтах == длина полученного массива `bytearray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_16x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эволюция изображения при декомпрессии\n",
    "Выглядит как увеличение фотографии в CSI: Место прреступления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lenna_gray_256x256, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = [1, 2, 4, 8]\n",
    "\n",
    "imgs = [comp.decompress(result_16x4, n) for n in n_iters]\n",
    "_, axs = plt.subplots(ncols=len(imgs), figsize=(18, 6))\n",
    "for index in range(len(imgs)):\n",
    "    axs[index].imshow(imgs[index], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиграемся с параметрами сжатия\n",
    "Понятно, что при увеличении перебора мы, во-первых, увеличиваем время вычислений, а во-вторых, улучшаем итоговое качество изображения после сжатия и декомпрессии.\n",
    "\n",
    "Чтобы увеличить перебор можно уменьшить размер шага `stride` или уменьшить размер доменного блока `block_size`. Но не рекомендуется делать блок размером меньше 4х4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_16x2 = comp.compress(lenna_gray_256x256, block_size=16, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = [1, 2, 4, 8]\n",
    "\n",
    "imgs = [comp.decompress(result_16x2, n) for n in n_iters]\n",
    "_, axs = plt.subplots(ncols=len(imgs), figsize=(18, 6))\n",
    "for index in range(len(imgs)):\n",
    "    axs[index].imshow(imgs[index], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_8x4 = comp.compress(lenna_gray_256x256, block_size=8, stride=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = [1, 2, 4, 8]\n",
    "\n",
    "imgs = [comp.decompress(result_8x4, n) for n in n_iters]\n",
    "_, axs = plt.subplots(ncols=len(imgs), figsize=(18, 6))\n",
    "for index in range(len(imgs)):\n",
    "    axs[index].imshow(imgs[index], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_8x2 = comp.compress(lenna_gray_256x256, block_size=8, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = [1, 2, 4, 8]\n",
    "\n",
    "imgs = [comp.decompress(result_8x2, n) for n in n_iters]\n",
    "_, axs = plt.subplots(ncols=len(imgs), figsize=(18, 6))\n",
    "for index in range(len(imgs)):\n",
    "    axs[index].imshow(imgs[index], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построим график качества\n",
    "Качество в данном случае будет измеряться по PSNR (а значит в децибелах).\n",
    "\n",
    "Это базовый график для понимания соотношения между коэффициентом сжатия и качеством, получаемым на выходе. Можно посмотреть, как он будет меняться в зависимости от количества итераций при декомпрессии, например."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_psnr(ref, img):\n",
    "    assert ref.shape == img.shape, \"Shape mismatch\"\n",
    "    if is_colored(img):\n",
    "        ref_yuv = rgb2yuv(ref)\n",
    "        img_yuv = rgb2yuv(img)\n",
    "        \n",
    "        return (4 * psnr(ref_yuv[..., 0], img_yuv[..., 0]) +\n",
    "                    psnr(ref_yuv[..., 1], img_yuv[..., 1]) +\n",
    "                    psnr(ref_yuv[..., 2], img_yuv[..., 2])\n",
    "               ) / 6\n",
    "    else:\n",
    "        return psnr(ref, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = [0, 20, 40, 60, 80, 100]\n",
    "\n",
    "def test_image(img):\n",
    "    compressed_images = [comp.compress2(img, quality=q) for q in quality]\n",
    "    decompressed_images = [comp.decompress(compressed) for compressed in compressed_images]\n",
    "    compression_rates = np.array([len(compressed) for compressed in compressed_images]) / img.size\n",
    "    psnrs = [weighted_psnr(img, decompressed) for decompressed in decompressed_images]\n",
    "    return compression_rates, psnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_plot_collection(collection):\n",
    "    _, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    for image in collection:\n",
    "        compression_rates, psnrs = test_image(image)\n",
    "        ax.plot(compression_rates, psnrs, marker='o', ms=10, ls='-.')\n",
    "\n",
    "    ax.set_xlabel('Compression Rate', fontsize=16)\n",
    "    ax.set_ylabel('PSNR, dB', fontsize=16)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_plot_collection([lenna_gray_256x256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = []\n",
    "for image_name in os.listdir('test_files'):\n",
    "    image = resize(io.imread(os.path.join('test_files', image_name)), (256, 256))\n",
    "    if is_colored(image):\n",
    "        image = np.rint(rgb2gray(image) * 255).astype('uint8')\n",
    "    collection.append(image)\n",
    "test_and_plot_collection(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улучшим алгоритм\n",
    "Одним из основных способов улучшения сжатия изображений является разбиение картинки не на равные блоки, а на блоки разных размеров. Как дополнительную часть задания, мы предлагаем реализовать разбиение квадродеревом, это позволит более гибко настраивать параметры сжатия и получить лучшие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Пример разбиения изображения на блоки с использованием квадродерева</center>\n",
    "\n",
    "Исходное изображение | Разбиение квадродеревом\n",
    "- | -\n",
    "![Source image](images/house.jpg) | ![Segmentation](images/quadtree.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
