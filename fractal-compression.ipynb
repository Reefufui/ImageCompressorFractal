{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание №2: Фрактальное сжатие\n",
    "\n",
    "ФИО: Трифонов Андрей Рафисович \n",
    "Группа: 213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Баллы за задание складываются из двух частей: баллы за выполнение промежуточных подзаданий и баллы за качество**\n",
    "\n",
    "**Максимальное количество баллов за выполнение промежуточных подзаданий — 15**\n",
    "\n",
    "**Баллы за качество выставляются по итогам сравнения всех решений**\n",
    "\n",
    "## Правила сдачи\n",
    "* У каждого подзадания указано максимальное количество баллов, которые можно за него получить\n",
    "* Для сдачи необходимо в Google Classroom загрузить Jupyter-ноутбук с выполненными подзаданиями\n",
    "* В некоторых ячейках есть строки (`# GRADED CELL: [function name]`), эти строки **менять нельзя**, они будет использоваться при проверке вашего решения\n",
    "* Интерфейс функций и классов помеченных таким образом должен остаться без изменений\n",
    "* Ячейка со строкой (`# GRADED CELL: [function name]`) должна содержать только **одну функцию или класс**\n",
    " * Лайфхак: функции можно определять внутри функций\n",
    "* Никакие другие ячейки не будут использованы при проверке, они должны быть самодостаточны\n",
    "* Запрещено импортировать иные библиотеки и функции, кроме указанных в первой ячейке с кодом  \n",
    "(если сильно захочется что-то еще импортировать, спросите в чате курса)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colored glitches comming soon...\n",
    "\n",
    "![Segmentation](glitches/attempt_2.jpg)\n",
    "![Source image](glitches/attempt_3.jpg)\n",
    "![Segmentation](glitches/corrupted_house.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python Library\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# Additional Modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from skimage import data, img_as_float64\n",
    "from skimage.metrics import mean_squared_error as mse, peak_signal_noise_ratio as psnr\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray, rgb2yuv, yuv2rgb\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_rgb_512x512 = io.imread('test_files/lenna.bmp')\n",
    "lenna_rgb_256x256 = resize(lenna_rgb_512x512, (256, 256))\n",
    "lenna_gray_256x256 = np.rint(rgb2gray(lenna_rgb_256x256) * 255).astype('uint8')\n",
    "\n",
    "boats_rgb_512x512 = io.imread('test_files/BoatsColor.bmp')\n",
    "boats_rgb_256x256 = resize(boats_rgb_512x512, (256, 256))\n",
    "boats_gray_256x256 = np.rint(rgb2gray(boats_rgb_256x256) * 255).astype('uint8')\n",
    "\n",
    "foxy_rgb_256x256 = io.imread('test_files/foxy_rgb_256x256.jpg')\n",
    "foxy_gray_256x256 = np.rint(rgb2gray(foxy_rgb_256x256) * 255).astype('uint8')\n",
    "\n",
    "house_rgb_512x512 = io.imread('images/house.jpg')\n",
    "house_rgb_256x256 = resize(house_rgb_512x512, (256, 256))\n",
    "house_gray_256x256 = np.rint(rgb2gray(house_rgb_256x256) * 255).astype('uint8')\n",
    "plt.imshow(house_gray_256x256, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общие функции\n",
    "В следующих клетках описаны функции и классы, которые будут использоваться **вами** при выполнении следующих подзаданий. Стоит с ними подробно ознакомиться, понять, что они делают, и поэкспериментировать.\n",
    "\n",
    "**Не следует их менять.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_num_bits(length, stride):\n",
    "    return np.ceil(np.log2(length / stride)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_colored(image):\n",
    "    if len(image.shape) == 2:\n",
    "        return False\n",
    "    elif len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "        return True\n",
    "    else:\n",
    "        message = 'Invalid shape of the image: `{}`'\n",
    "        raise ValueError(message.format(image.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 балла] Функция для нахождения наилучшего преобразования рангового блока\n",
    "\n",
    "#### Описание\n",
    "\n",
    "на входе функции подаются:\n",
    "* исходное Ч/Б изображение (`image`)\n",
    "* уменьшенное изображение (`resized_image`)\n",
    "* координаты рангового блока (`x`, `y`)\n",
    "* размер блока (`block_size`)\n",
    "* шаг, через сколько пикселей перескакивать при переборе (`stride`)\n",
    "\n",
    "на выходе функция должна выдавать:\n",
    "* лучшее преобразование в смысле MSE, объект типа `BlockTransform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: find_block_transform\n",
    "\n",
    "def find_block_transform(image, resized_image, x, y, block_size=8, stride=1, intensity=0.75):\n",
    "    '''Find best transformation for given rank block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source B/W image.\n",
    "\n",
    "    resized_image: np.array\n",
    "        Resized source image.\n",
    "\n",
    "    x, y: int, int\n",
    "        Coordinates of the rank block.\n",
    "    \n",
    "    block_size: int\n",
    "        Size of rank block.\n",
    "\n",
    "    stride: int\n",
    "        Vertical and horizontal stride for domain block search.\n",
    "    \n",
    "    intensity: float (DEPATCHED)\n",
    "        Brightness scaling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_transform: BlockTransform\n",
    "        Best transformation.\n",
    "    '''\n",
    "    \n",
    "    trs = np.arange(8)\n",
    "    domain_xs = np.arange(0, resized_image.shape[0] - block_size + 1, stride)\n",
    "    domain_ys = np.arange(0, resized_image.shape[1] - block_size + 1, stride)\n",
    "    \n",
    "    def img2domain_blocks(img):\n",
    "        domain_blocks = []\n",
    "        \n",
    "        imgs4trs = np.array([img for tr in trs])\n",
    "        for tr in range(1, 8):\n",
    "            imgs4trs[tr] = np.rot90(imgs4trs[tr - 1])\n",
    "        for tr in range(4, 8):\n",
    "            imgs4trs[tr] = np.fliplr(imgs4trs[tr])\n",
    "        \n",
    "        for tr, dm_x, dm_y in itertools.product(trs, domain_xs, domain_ys):\n",
    "            domain_blocks.append(imgs4trs[tr][dm_x:(dm_x + block_size),\n",
    "                                              dm_y:(dm_y + block_size)])\n",
    "        return domain_blocks\n",
    "    \n",
    "    # we may want to have a prebuilt array of domain blocks\n",
    "    if ((x, y) == (0, 0)):\n",
    "        find_block_transform.db_cache = img2domain_blocks(resized_image)\n",
    "    \n",
    "    domain_blocks = find_block_transform.db_cache # fetch Dij from cache\n",
    "    rank_block = image[x:(x + block_size), y:(y + block_size)]\n",
    "    pixels_in_block = block_size * block_size\n",
    "    \n",
    "    min_distance = 100000000000\n",
    "    domain_block_ID = 0\n",
    "    for tr, dm_x, dm_y in itertools.product(trs, domain_xs, domain_ys):\n",
    "        domain_block = domain_blocks[domain_block_ID]\n",
    "        domain_block_ID += 1\n",
    "        di = (np.sum(rank_block) - intensity * np.sum(domain_block)) / pixels_in_block\n",
    "        current_distance = np.sum( np.square(domain_block * iy +\n",
    "                                            di - rank_block) )\n",
    "        if (current_distance < min_distance):\n",
    "            min_distance = current_distance\n",
    "            best_transform = BlockTransform(dm_x, dm_y, (int)(di), (int)(iy), tr)\n",
    "    \n",
    "    return best_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 балла] Применение IFS к изображению\n",
    "\n",
    "#### Описание\n",
    "\n",
    "на входе функции подаются:\n",
    "* исходное изображение (`image`)\n",
    "* уменьшенное изображение (`resized_image`)\n",
    "* IFS, массив объектов типа `BlockTransform` (`transforms`)\n",
    "* размер блока (`block_size`)\n",
    "\n",
    "на выходе функция должна выдавать:\n",
    "* картинку после одинарного применения IFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: perform_transform\n",
    "\n",
    "def perform_transform(image, resized_image, transforms, block_size):\n",
    "    '''Perform IFS on given image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source image.\n",
    "\n",
    "    resized_image: np.array\n",
    "        Resized source image.\n",
    "\n",
    "    transforms: list of BlockTransform's\n",
    "        Given IFS, Iterated Function System\n",
    "    \n",
    "    block_size: int\n",
    "        Size of rank block.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_image: np.array\n",
    "        Transformed image.\n",
    "    '''\n",
    "    \n",
    "    # genrating and image for all 90˚ rotations + mirror\n",
    "    def img_4_blocks(img):\n",
    "        trs = np.arange(8) \n",
    "        img_and_trs = np.array([resized_image for tr in trs])\n",
    "        \n",
    "        for tr in range(1, 8):\n",
    "            img_and_trs[tr] = np.rot90(img_and_trs[tr - 1])\n",
    "        for tr in range(4, 8):\n",
    "            img_and_trs[tr] = np.fliplr(img_and_trs[tr])\n",
    "            \n",
    "        return img_and_trs\n",
    "    \n",
    "    xs = np.arange(0, image.shape[0], block_size)\n",
    "    ys = np.arange(0, image.shape[1], block_size)\n",
    "    \n",
    "    transformed_image = image\n",
    "    \n",
    "    transform_ID = 0\n",
    "    imgs = img_4_blocks(resized_image)\n",
    "\n",
    "    for x, y in itertools.product(xs, ys):\n",
    "        t = transforms[transform_ID]\n",
    "        transform_ID += 1\n",
    "        transformed_image[x:(x + block_size),\n",
    "                          y:(y + block_size)\n",
    "            ] = t.iy * imgs[t.tr][t.x:(t.x + block_size), t.y:(t.y + block_size)] + t.di\n",
    "\n",
    "    return transformed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [7 баллов] Класс, реализующий интерфейс битового массива\n",
    "Он понадобится для преобразования найденной IFS в строку, чтобы записать сжатый файл на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: BitBuffer\n",
    "\n",
    "class BitBuffer:\n",
    "    '''Class that provides storing and and reading integer numbers \n",
    "    in continuous bytearray.\n",
    "    \n",
    "    !!! BitBuffer is FIFO data structure !!!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    buffer : bytearray, optional (default=None)\n",
    "        Input bytearray, for initialization.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _buffer : bytearray\n",
    "        Bytearray that can contain any information.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> buffer = BitBuffer()\n",
    "    >>> buffer.push(1, 1)\n",
    "    >>> x = buffer.pop(1)\n",
    "    >>> print(x)\n",
    "    1\n",
    "    >>> buffer.push(125, 18)\n",
    "    >>> x = buffer.pop(18)\n",
    "    >>> print(x)\n",
    "    125\n",
    "    >>> buffer.push(5, 3)\n",
    "    >>> x = buffer.pop(3)\n",
    "    >>> print(x)\n",
    "    5\n",
    "\n",
    "    >>> dy = transform.y // stride\n",
    "    >>> buffer.push(dy, self._num_bits_ver)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, buffer=None):\n",
    "        self._buffer = buffer or bytearray()\n",
    "        # already (written/read) bits by previous (push/pop)\n",
    "        self._bits2ignore_push = 0\n",
    "        self._bits2ignore_pop = 0\n",
    "\n",
    "    def to_bytearray(self):\n",
    "        '''Convert to bytearray.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        buffer: bytearray\n",
    "            Bytearray that contains all data.\n",
    "        '''\n",
    "        \n",
    "        return self._buffer\n",
    "\n",
    "    def push(self, x, n_bits):\n",
    "        '''Push given integer to buffer. (append)\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : int\n",
    "            Input number.\n",
    "\n",
    "        n_bits: int\n",
    "            Number of bits for store input number,\n",
    "            should be greater than log2(x).\n",
    "        '''\n",
    "        \n",
    "        # shift x's bits closer to ending of written bits (b)\n",
    "        #                         (i i i) <- self._bits2ignore_push (written already)\n",
    "        # ... | b b b b  b b b b | b b b -  - - - - |\n",
    "        #                                x  x x 0 0 <- gap_remover (0)\n",
    "        \n",
    "        # (gap_remover == 8) <= (self._bits2ignore_push + n_bits == 8 * n), n > 0\n",
    "        # if so ending will be byte-like\n",
    "        \n",
    "        #print(\"debug dump 4 x=\", x)\n",
    "        gap_remover = 8 - (self._bits2ignore_push + n_bits) % 8 # [0; 8]\n",
    "        not_byte_sized = 1 if (gap_remover != 8) else 0\n",
    "        gap_remover %= 8 # preventing 8 bit x shift\n",
    "        x <<= gap_remover\n",
    "        \n",
    "        bytes_to_push = (self._bits2ignore_push + n_bits) // 8 + not_byte_sized\n",
    "        x = np.int64(x)\n",
    "        x_bytes = (x.item()).to_bytes(bytes_to_push, byteorder=\"big\", signed=False)\n",
    "        \n",
    "        # merge x's first and buffer's last byte\n",
    "        if (self._bits2ignore_push):\n",
    "            #print(\"gap remover:\", gap_remover)\n",
    "            #print(\"2ignore :\", self._bits2ignore_push)\n",
    "            #print(\"ending of buffer: \", self._buffer[-1], \"; ending of x_bytes: \", x_bytes)\n",
    "            self._buffer[-1] += x_bytes[0]\n",
    "            x_bytes = x_bytes[1:] # we dont want to append x's first later\n",
    "        \n",
    "        for byte in x_bytes:\n",
    "            self._buffer.append(byte)\n",
    "        \n",
    "        self._bits2ignore_push = (8 - gap_remover) % 8\n",
    "        \n",
    "    def pop(self, n_bits):\n",
    "        '''Pop n_bits from buffer and transform it to a number.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_bits: int\n",
    "            Number of bits for pop from buffer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x: int\n",
    "            Extracted number.\n",
    "        '''\n",
    "        \n",
    "        #print(self._bits2ignore_pop)\n",
    "        \n",
    "        #  (i i i)  <- self._bits2ignore_pop (read already)\n",
    "        # | ? ? ? x  x x x x | x b b b  b b b b | ...\n",
    "        # | ? ? ? x  x x x x | x(b b b  b b b b) <- aligner\n",
    "        # | ? ? ? ?  ? ? ? ? | ? ? x  x x x x x\n",
    "        \n",
    "        # (aligner == 8) <= (self._bits2ignore_pop + n_bits == 8 * n), n > 0\n",
    "        # if so beginning will be byte-like\n",
    "        \n",
    "        aligner = 8 - (self._bits2ignore_pop + n_bits) % 8 # [0; 8]\n",
    "        not_byte_sized = 1 if (aligner != 8) else 0\n",
    "        aligner %= 8 # preventing 8 bit x shift\n",
    "        \n",
    "        bytes_to_pop = (self._bits2ignore_pop + n_bits) // 8\n",
    "        bytes_to_read = bytes_to_pop + not_byte_sized\n",
    "        x_bytes = self._buffer[:bytes_to_read]\n",
    "        \n",
    "        x = int.from_bytes(x_bytes, byteorder='big', signed=False)\n",
    "        x >>= aligner\n",
    "        x &= 2 ** n_bits - 1\n",
    "        \n",
    "        self._buffer = self._buffer[bytes_to_pop:]\n",
    "        self._bits2ignore_pop = (8 - aligner) % 8\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Баллы за качество] Класс, реализующий интерфейс архиватора изображений\n",
    "\n",
    "#### Условие\n",
    "* Класс будет тестироваться как на черно-белых, так и на **цветных** изображениях\n",
    "* Для цветных изображений необходимо переходить в YUV, сжимать, а потом обратно в RGB для финального результата\n",
    "* В качестве оценки алгоритма будет использоваться кривая размер-качество, построенная на основе запуска метода compress2, с параметрами качества [0, 20, 40, 60, 80, 100]\n",
    "* Следует обеспечить непрерывную монотонную зависимость реального качества декодированного изображения от параметра качества\n",
    "* Баллы будут выставляться исходя из того, насколько построенный график размер-качество лежит близко к верхнему левому углу (высокое качество и низкий размер)\n",
    "* За красивые графики с равномерно распределенными узлами [0 ... 100] и без точек перегиба выставляются дополнительные баллы\n",
    "* Ограничение времени работы (суммарно сжатие и разжатие) на всех уровнях качества: 8 минут\n",
    "\n",
    "**Интерфейсом данного класса считаются только методы compress2 и decompress, остальные можно менять как угодно**`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: FractalCompressor\n",
    "\n",
    "'''\n",
    "    My types for tests (allowed -- telegram 9:19 29.10)\n",
    "        BlockTransform:\n",
    "            x - domain block offset (x)    int\n",
    "            y - domain block offset (y)    int\n",
    "            di - brightness scale          int\n",
    "            iy - intensity scale           int\n",
    "            neg - for negative intesity    int [0..1]\n",
    "            tr - symmetry                  int [0..7]\n",
    "        FractalCompressionParams:\n",
    "            height - height of image in pixels     int\n",
    "            width - width of image in pixels       int\n",
    "            is_colored - rgb or grayscale          int [0, 1]\n",
    "            min_block_size - min range block size  int\n",
    "            stride - pixels to skip when searching int\n",
    "'''\n",
    "BlockTransform = namedtuple('BlockTransform', ['x', 'y', 'di', 'iy', 'neg', 'tr'])\n",
    "FractalCompressionParams = namedtuple(\n",
    "    'FractalCompressionParams', [\n",
    "        'height',\n",
    "        'width',\n",
    "        'is_colored',\n",
    "        'min_block_size',\n",
    "        'stride'\n",
    "    ]\n",
    ")\n",
    "\n",
    "class FractalCompressor:\n",
    "    def __init__(self):\n",
    "        self._num_bits_ver = None\n",
    "        self._num_bits_hor = None\n",
    "        self._num_bits_pix = 9\n",
    "        self._num_bits_iny = 7\n",
    "        self._num_bits_tfm = 3\n",
    "    \n",
    "    def _add_header(self, buffer, params):\n",
    "        buffer.push(params.height, 11)\n",
    "        buffer.push(params.width, 11)\n",
    "        buffer.push(1 if (params.is_colored) else 0, 1)\n",
    "        buffer.push(params.min_block_size, 10)\n",
    "        buffer.push(params.stride, 9)\n",
    "    \n",
    "    def _read_header(self, buffer):\n",
    "        params = FractalCompressionParams(\n",
    "            buffer.pop(11),\n",
    "            buffer.pop(11),\n",
    "            buffer.pop(1) == 1,\n",
    "            buffer.pop(10),\n",
    "            buffer.pop(9)\n",
    "        )\n",
    "        return params\n",
    "    \n",
    "    def _add_to_buffer(self, buffer, transform, stride):\n",
    "        di_negative_flag = 1 if (transform.di < 0) else 0\n",
    "        di_unsigned = (abs(transform.di) << 1) + di_negative_flag\n",
    "        \n",
    "        buffer.push((int)( (transform.x / stride)  ), self._num_bits_hor)\n",
    "        buffer.push((int)( (transform.y / stride)  ), self._num_bits_ver)\n",
    "        buffer.push((int)(  di_unsigned            ), self._num_bits_pix)\n",
    "        buffer.push((int)(  transform.iy           ), self._num_bits_iny)\n",
    "        buffer.push((int)(  transform.neg          ), 1                 )\n",
    "        buffer.push((int)( (transform.tr)          ), self._num_bits_tfm)\n",
    "        \n",
    "    def _read_transform(self, buffer, stride):\n",
    "        x = buffer.pop(self._num_bits_hor) * stride\n",
    "        y = buffer.pop(self._num_bits_ver) * stride\n",
    "        di_unsigned = buffer.pop(self._num_bits_pix)\n",
    "        di = (-1 if (di_unsigned % 2 == 1) else 1) * (di_unsigned >> 1)\n",
    "        iy = buffer.pop(self._num_bits_iny)\n",
    "        neg = buffer.pop(1)\n",
    "        tr = buffer.pop(self._num_bits_tfm)\n",
    "        transform = BlockTransform (\n",
    "            x, y, di, iy, neg, tr\n",
    "        )\n",
    "        \n",
    "        return transform\n",
    "    \n",
    "    def _quad_tree(self, image, resized_image, min_block_size=8, stride=4):\n",
    "        trs = np.arange(8) # All 90˚ rotations and 'flections\n",
    "        thrasholds = [10000, 10000, 10000, 10000, 10000]\n",
    "        \n",
    "        # Initial quad tree split.\n",
    "        rank_coords_pool = [_ for _ in itertools.product([0, 256//2], [0, 256//2])]\n",
    "        \n",
    "        # Make empty quad tree layers.\n",
    "        levels = [level for level in range(1 + int(np.log2(64 // min_block_size)))]\n",
    "        def layer_grid(level, initial=None):\n",
    "            return [[initial for _ in range(2**(level + 2))] for _ in range(2**(level + 2))]\n",
    "        layers = [layer_grid(l, -1) for l in levels]\n",
    "        sums_A = [layer_grid(l, 0) for l in levels]\n",
    "        sums_A2 = [layer_grid(l, 0) for l in levels]\n",
    "        map_M = [layer_grid(l, 0.0) for l in levels]\n",
    "        \n",
    "        # DEBUG APPLICATION\n",
    "        #application = (np.copy(image - image)).astype('float64')\n",
    "        \n",
    "        transforms = []\n",
    "        \n",
    "        # Fill this layers and write 'layers' to buffer\n",
    "        for level in range(len(levels) + 1):\n",
    "            # Stating with 64 Rank block size.\n",
    "            block_size = 64 // (2 ** level)\n",
    "            #sub_block_size = block_size // 2\n",
    "            if (block_size == min_block_size):\n",
    "                thrasholds[level] = 1000000000 # LAME => REWORK\n",
    "            pix_in_block = block_size ** 2\n",
    "            \n",
    "            # Neat quad tree split by only adding 3 Rank block offsets to the pool.\n",
    "            for point in rank_coords_pool.copy():\n",
    "                rank_coords_pool.append((point[0], point[1] + block_size))\n",
    "                rank_coords_pool.append((point[0] + block_size, point[1]))\n",
    "                rank_coords_pool.append((point[0] + block_size, point[1] + block_size))\n",
    "            \n",
    "            domain_offsets = np.arange(0, resized_image.shape[0] - block_size + 1, stride)\n",
    "            rank_coords = rank_coords_pool.copy()\n",
    "            \n",
    "            # Write previous layer of quad tree to buffer.\n",
    "            if (level != 0):\n",
    "                for row in layers[level - 1]:\n",
    "                    for t in row:\n",
    "                        if (t == 0):\n",
    "                            # Not founded.\n",
    "                            transforms.append(0)\n",
    "                        elif (t != -1):\n",
    "                            # Found one.\n",
    "                            transforms.append(t)\n",
    "                            \n",
    "            elif (level == len(levels)):\n",
    "                break #TODO WRITE PIXELS\n",
    "            \n",
    "            for r_x, r_y in rank_coords:\n",
    "                # Cut Rank block.\n",
    "                rank_block = (image[r_x:(r_x + block_size),\n",
    "                                    r_y:(r_y + block_size)]).astype('float64')\n",
    "                # Indices for current layer\n",
    "                c_x, c_y = r_x // block_size, r_y // block_size\n",
    "                \n",
    "                # Declare that we realy tried to search for this Rank block.\n",
    "                layers[level][c_x][c_y] = 0\n",
    "                \n",
    "                # Find brightness sums for average error evaluation.\n",
    "                sums_A[level][c_x][c_y] = np.sum(rank_block, dtype='float64')\n",
    "                sums_A2[level][c_x][c_y] = np.sum(np.square(rank_block, dtype='float64'),\n",
    "                                                  dtype='float64')\n",
    "                \n",
    "                ''' CONCEPT\n",
    "                #sum_i = 0\n",
    "                #s = [0, 0, 0, 0]\n",
    "                #for i, j in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "                #    s[sum_i] = sums_A[level + 1][n_x + i, n_y + j] = np.sum(\n",
    "                #        rank_block[(r_x + i*sub_block_size):(r_x + (i+1)*sub_block_size),\n",
    "                #                   (r_y + j*sub_block_size):(r_y + (j+1)*sub_block_size)],\n",
    "                #            dtype='float64')\n",
    "                #    sum_i++\n",
    "                #code_A[level][c_x][c_y] = [s[0] > s[1], s[0] > s[2],\n",
    "                #                           s[1] > s[3], s[2] > s[3]]\n",
    "                '''\n",
    "            \n",
    "            for d_x, d_y in tqdm(itertools.product(domain_offsets,\n",
    "                                                   domain_offsets),\n",
    "                                 total=len(domain_offsets)*len(domain_offsets)):\n",
    "                # Cut Domain block.\n",
    "                domain_block = (resized_image[d_x:(d_x + block_size),\n",
    "                                              d_y:(d_y + block_size)]).astype('float64')\n",
    "                \n",
    "                # Find brightness sums for average error evaluation.\n",
    "                B = np.sum(domain_block, dtype='float64')\n",
    "                B2 = np.sum(np.square(domain_block, dtype='float64'), dtype='float64')\n",
    "                \n",
    "                # Parse through Rank blocks in this layer's Rank block pool.\n",
    "                for r_x, r_y in rank_coords:\n",
    "                    # Cut Rank block. (NOT EFFECTIVE => BETTER HAVE PREBUILT ARRAY)\n",
    "                    rank_block = (image[r_x:(r_x + block_size),\n",
    "                                        r_y:(r_y + block_size)]).astype('float64')\n",
    "                    # Find sums for average error evaluation.\n",
    "                    ''' DEPATCHED\n",
    "                    A = np.sum(rank_block, dtype='float64')\n",
    "                    A2 = np.sum(np.square(rank_block, dtype='float64'), dtype='float64')\n",
    "                    '''\n",
    "                    # Indices for 'layers' and 'M_map'\n",
    "                    l_x = r_x // block_size\n",
    "                    l_y = r_y // block_size\n",
    "                    \n",
    "                    # 2 ARRAYS - LAME AND NOT FAST\n",
    "                    A = sums_A[level][l_x][l_y]\n",
    "                    A2 = sums_A2[level][l_x][l_y]\n",
    "                    \n",
    "                    # Parse through all rotations and 'flections of Domain block.\n",
    "                    for tr in trs:\n",
    "                        # COPMARE BRIGHTNESS CODE HERE - TODO\n",
    "                        \n",
    "                        # The only thing that changes when we rotate is                 #(sum: a*b).\n",
    "                        AB = np.sum(np.multiply(domain_block, rank_block, dtype='float64'),\n",
    "                            dtype='float64')\n",
    "                        \n",
    "                        # Evaluate best brightness 'p' and intensity 'q' transformations.\n",
    "                        q = (pix_in_block * AB - A * B) / (pix_in_block * B2 - B * B)\n",
    "                        \n",
    "                        # INTENSITY GUARD\n",
    "                        q = 0.99 if (q >= 1.0) else q\n",
    "                        q = -0.99 if (q <= -1.0) else q\n",
    "                        q = round(q, 2)\n",
    "                        p = (AB - B2 * abs(q)) / B\n",
    "                        \n",
    "                        # DEPATCHED 'q' and 'p' FOR DEBUG\n",
    "                        '''\n",
    "                        q = 0.75\n",
    "                        p = (A - 0.75 * B) / pix_in_block\n",
    "                        p = round(p, 2)\n",
    "                        M = np.sum(np.square(q * domain_block + p - rank_block,\n",
    "                                             dtype='float64'), dtype='float64')\n",
    "                        '''\n",
    "                        \n",
    "                        # NAN GUARD\n",
    "                        if (p == p):\n",
    "                            p = round(p)\n",
    "                            # Evaluate average error.\n",
    "                            M = q*q*B2 + A2 + pix_in_block*p*p - 2*(q*(AB - p * B) + p*A)\n",
    "                        \n",
    "                        # Check if M satisfies criteria\n",
    "                        if ((p == p) and (abs(M) < thrasholds[level])):\n",
    "                            if ((r_x, r_y) in rank_coords_pool):\n",
    "                                if (q >= 0):\n",
    "                                    #['x', 'y', 'di', 'iy', 'neg', 'tr']\n",
    "                                    layers[level][l_x][l_y] = 0\n",
    "                                    layers[level][l_x][l_y] = BlockTransform(\n",
    "                                        d_x, d_y, int(p), int(q * 100), 0, tr\n",
    "                                    )\n",
    "                                    #application[r_x:(r_x+block_size), \n",
    "                                    #    r_y:(r_y+block_size)] = q * domain_block + p\n",
    "                                else:\n",
    "                                    layers[level][l_x][l_y] = 0\n",
    "                                    layers[level][l_x][l_y] = BlockTransform(\n",
    "                                        d_x, d_y, int(p), -int(q * 100), 1, tr\n",
    "                                    )\n",
    "                                    #application[r_x:(r_x+block_size), \n",
    "                                    #    r_y:(r_y+block_size)] = - q * (255 - domain_block) - p\n",
    "                                map_M[level][l_x][l_y] = M\n",
    "                                rank_coords_pool.remove((r_x, r_y))\n",
    "                                #print(r_x, r_y, \" -- \", d_x, d_y)\n",
    "                            elif (M < map_M[level][l_x][l_y]):\n",
    "                                #print(\"\\t\\tfound !better! for\\t\", l_x, l_y, \":\", M)\n",
    "                                if (q >= 0):\n",
    "                                    layers[level][l_x][l_y] = 0\n",
    "                                    layers[level][l_x][l_y] = BlockTransform(\n",
    "                                        d_x, d_y, int(p), int(q * 100), 0, tr\n",
    "                                    )\n",
    "                                    #application[r_x:(r_x+block_size), \n",
    "                                    #    r_y:(r_y+block_size)] = q * domain_block + p\n",
    "                                else:\n",
    "                                    layers[level][l_x][l_y] = 0\n",
    "                                    layers[level][l_x][l_y] = BlockTransform(\n",
    "                                        d_x, d_y, int(p), -int(q * 100), 1, tr\n",
    "                                    )\n",
    "                                    #application[r_x:(r_x+block_size), \n",
    "                                    #    r_y:(r_y+block_size)] = - q * (255 - domain_block) - p\n",
    "                                map_M[level][l_x][l_y] = M\n",
    "                                #print(r_x, r_y, \" -- \", d_x, d_y)\n",
    "                            \n",
    "                        # Rotate Domain block\n",
    "                        domain_block = np.rot90(domain_block)\n",
    "                        domain_block = domain_block if ((tr+1)%4!=0) else np.fliplr(domain_block)\n",
    "        \n",
    "        #heat_map = np.rint(np.array(map_M[1])).astype('int')\n",
    "        #application = (application).astype('uint8')\n",
    "        #plt.imshow(application, cmap='gray')\n",
    "        \n",
    "        return transforms\n",
    "    \n",
    "    def _disassemble_rgb(self, img_rgb):\n",
    "        def yuv_converter(img_rgb, vec, downscale):\n",
    "            y_u_v = np.dot(img_rgb[...], vec)\n",
    "            if (downscale):\n",
    "                shape_of_uv = ( int(img_rgb.shape[0] * 0.5), int(img_rgb.shape[1] * 0.5) )\n",
    "                y_u_v = resize(y_u_v, shape_of_uv, preserve_range=True)\n",
    "            return y_u_v\n",
    "        \n",
    "        image_y = yuv_converter(img_rgb, [0.299, 0.587, 0.114], downscale=False)\n",
    "        image_u = yuv_converter(img_rgb, [-0.14713, -0.28886, 0.436], downscale=True)\n",
    "        image_v = yuv_converter(img_rgb, [0.615, -0.51499, -0.10001], downscale=True)\n",
    "        \n",
    "        return image_y, image_u, image_v\n",
    "\n",
    "    def _assemble_rgb(self, img_y, img_u, img_v):\n",
    "        img_rgb = np.zeros((img_y.shape[0], img_y.shape[1], 3), dtype='uint8')\n",
    "        restored_shape = (img_y.shape[0], img_y.shape[1])\n",
    "        img_u = resize(img_u, restored_shape, preserve_range=True)\n",
    "        img_v = resize(img_v, restored_shape, preserve_range=True)\n",
    "        \n",
    "        img_rgb[...,0] = img_y + 1.13983 * img_v\n",
    "        img_rgb[...,1] = img_y - 0.39465 * img_u - 0.58060 * img_v\n",
    "        img_rgb[...,2] = img_y + 2.03211 * img_u\n",
    "        \n",
    "        return np.rint(img_rgb).astype('uint8')\n",
    "        \n",
    "    def _compress(self, params, image_y, image_u=None, image_v=None):\n",
    "        buffer = BitBuffer()\n",
    "        resized_image = resize(image_y, (128, 128), preserve_range=True)\n",
    "        \n",
    "        self._num_bits_ver = derive_num_bits(256, params.stride)\n",
    "        self._num_bits_hor = derive_num_bits(256, params.stride)\n",
    "        \n",
    "        buffer = BitBuffer()\n",
    "        self._add_header(buffer, params)\n",
    "        transforms = self._quad_tree(image_y, resized_image, params.min_block_size)\n",
    "        buffer.push(int(len(transforms)), 15)\n",
    "        for t in transforms:\n",
    "            if (t == 0):\n",
    "                buffer.push(0, 1) # Split!\n",
    "            else:\n",
    "                buffer.push(1, 1) # Found one.\n",
    "                self._add_to_buffer(buffer, t, params.stride)\n",
    "        \n",
    "        #print(transforms)\n",
    "        return buffer.to_bytearray()\n",
    "        \n",
    "    def compress2(self, image, quality=50):\n",
    "        '''Compress input image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    "\n",
    "        quality: int, optional (default=50)\n",
    "            Quality of image compression\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `decompress`.\n",
    "        '''\n",
    "        \n",
    "        min_block_sizes = [64, 32, 16, 16, 8, 4, 4]\n",
    "        params = FractalCompressionParams(\n",
    "            height = image.shape[0],\n",
    "            width = image.shape[1],\n",
    "            is_colored = is_colored(image),\n",
    "            min_block_size = min_block_sizes[quality//20],\n",
    "            stride = 4\n",
    "        )\n",
    "        \n",
    "        # IMAGE SIZE GUARD\n",
    "        if (image.shape[0] != 256):\n",
    "            image = np.rint(resize(image, (256, 256), preserve_range=True)).astype('uint8')\n",
    "        \n",
    "        if (params.is_colored):\n",
    "            # TODO\n",
    "            image_y, image_u, image_v = self._disassemble_rgb(image)\n",
    "            #y_params = uv_params = params\n",
    "            #y_params.is_colored = uv_params.is_colored = False\n",
    "            #uv_params.height = uv_params.width = y_params.height * 0.5\n",
    "\n",
    "            #byte_array = self._compress(params, image_y, image_u, image_v)\n",
    "        else:\n",
    "            byte_array = self._compress(params, image)\n",
    "        \n",
    "        return byte_array\n",
    "    \n",
    "    def _perform_transform_qt(self, transforms, min_block_size, image, stride):\n",
    "        resized_image = resize(image, (128, 128), preserve_range=True)\n",
    "        levels = [level for level in range(1 + int(np.log2(64 // min_block_size)))]\n",
    "        \n",
    "        rank_coords_pool = [_ for _ in itertools.product([0, 256//2], [0, 256//2])]\n",
    "        transform_ID = 0\n",
    "        \n",
    "        for level in range(len(levels) + 1):\n",
    "            block_size = 64 // (2 ** level)\n",
    "            \n",
    "            # Neat quad tree split by only adding 3 Rank block offsets to the pool.\n",
    "            for point in rank_coords_pool.copy():\n",
    "                rank_coords_pool.append((point[0], point[1] + block_size))\n",
    "                rank_coords_pool.append((point[0] + block_size, point[1]))\n",
    "                rank_coords_pool.append((point[0] + block_size, point[1] + block_size))\n",
    "            \n",
    "            # Lame, but fine for now.\n",
    "            rank_coords_pool = sorted(rank_coords_pool, key=lambda x: x[1])\n",
    "            rank_coords_pool = sorted(rank_coords_pool, key=lambda x: x[0])\n",
    "            \n",
    "            rank_coords = rank_coords_pool.copy()\n",
    "            \n",
    "            for r_x, r_y in rank_coords:\n",
    "                if (transforms[transform_ID] != 0):\n",
    "                    t = transforms[transform_ID]\n",
    "                    domain_block = resized_image[t.x:(t.x + block_size),\n",
    "                                                 t.y:(t.y + block_size)]\n",
    "                    if (t.tr >= 4):\n",
    "                        domain_block = np.fliplr(domain_block)\n",
    "                    for tr in range(1, t.tr % 4 + 1):\n",
    "                        domain_block = np.rot90(domain_block)\n",
    "                    \n",
    "                    if (t.neg == 1):\n",
    "                        image[r_x:(r_x+block_size),\n",
    "                              r_y:(r_y+block_size)] = - (t.iy / 100) * (255 - domain_block) - t.di\n",
    "                    else:\n",
    "                        image[r_x:(r_x+block_size),\n",
    "                              r_y:(r_y+block_size)] = (t.iy / 100) * domain_block + t.di\n",
    "                        \n",
    "                    rank_coords_pool.remove((r_x, r_y))\n",
    "                    \n",
    "                transform_ID += 1\n",
    "                \n",
    "        return image\n",
    "    \n",
    "    def decompress(self, byte_array, num_iters=10):\n",
    "        '''Decompress input image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "\n",
    "        num_iters: int, optional (default=10)\n",
    "            Number of iterations to perform IFS.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image: np.array\n",
    "            Decompressed image.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `compress`.\n",
    "        '''\n",
    "        buffer = BitBuffer(byte_array)\n",
    "        \n",
    "        params = self._read_header(buffer)\n",
    "        self._num_bits_ver = derive_num_bits(256, params.stride)\n",
    "        self._num_bits_hor = derive_num_bits(256, params.stride)\n",
    "        \n",
    "        len_of_transforms = buffer.pop(15)\n",
    "        transforms = []\n",
    "        \n",
    "        for _ in range(len_of_transforms):\n",
    "            split_index = buffer.pop(1)\n",
    "            if (split_index == 1):\n",
    "                # Proceed transform\n",
    "                transforms.append(self._read_transform(buffer, params.stride))\n",
    "            else:\n",
    "                # Split!\n",
    "                transforms.append(0)\n",
    "        \n",
    "        image = np.zeros((256, 256), dtype='uint8')\n",
    "        for _ in range(num_iters):\n",
    "            image = self._perform_transform_qt(transforms, params.min_block_size, image, params.stride)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp = FractalCompressor()\n",
    "out_compress2 = comp.compress2(boats_gray_256x256, quality=0)\n",
    "plt.imshow(comp.decompress(out_compress2, 10), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построим график качества\n",
    "Качество в данном случае будет измеряться по PSNR (а значит в децибелах).\n",
    "\n",
    "Это базовый график для понимания соотношения между коэффициентом сжатия и качеством, получаемым на выходе. Можно посмотреть, как он будет меняться в зависимости от количества итераций при декомпрессии, например."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_psnr(ref, img):\n",
    "    assert ref.shape == img.shape, \"Shape mismatch\"\n",
    "    if is_colored(img):\n",
    "        ref_yuv = rgb2yuv(ref)\n",
    "        img_yuv = rgb2yuv(img)\n",
    "        \n",
    "        return (4 * psnr(ref_yuv[..., 0], img_yuv[..., 0]) +\n",
    "                    psnr(ref_yuv[..., 1], img_yuv[..., 1]) +\n",
    "                    psnr(ref_yuv[..., 2], img_yuv[..., 2])\n",
    "               ) / 6\n",
    "    else:\n",
    "        return psnr(ref, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = [0, 20, 40, 60, 80, 100]\n",
    "\n",
    "def test_image(img):\n",
    "    compressed_images = [comp.compress2(img, quality=q) for q in quality]\n",
    "    decompressed_images = [comp.decompress(compressed) for compressed in compressed_images]\n",
    "    compression_rates = np.array([len(compressed) for compressed in compressed_images]) / img.size\n",
    "    psnrs = [weighted_psnr(img, decompressed) for decompressed in decompressed_images]\n",
    "    return compression_rates, psnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_plot_collection(collection):\n",
    "    _, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    for image in collection:\n",
    "        compression_rates, psnrs = test_image(image)\n",
    "        ax.plot(compression_rates, psnrs, marker='o', ms=10, ls='-.')\n",
    "\n",
    "    ax.set_xlabel('Compression Rate', fontsize=16)\n",
    "    ax.set_ylabel('PSNR, dB', fontsize=16)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_plot_collection([lenna_gray_256x256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = []\n",
    "for image_name in os.listdir('test_files'):\n",
    "    image = resize(io.imread(os.path.join('test_files', image_name)), (256, 256))\n",
    "    if is_colored(image):\n",
    "        image = np.rint(rgb2gray(image) * 255).astype('uint8')\n",
    "    collection.append(image)\n",
    "test_and_plot_collection(collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
